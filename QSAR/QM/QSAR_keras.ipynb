{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the 0 split\n",
      "(5732,)\n",
      "(5732, 529)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid argument 'verbose' passed to K.function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-97ca1c5f0497>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mean_squared_error\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rmsprop\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peng/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    407\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                               sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/peng/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peng/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    668\u001b[0m                                              \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                                              \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m                                              **self._function_kwargs)\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peng/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfunction_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Invalid argument '%s' passed to K.function\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid argument 'verbose' passed to K.function"
     ]
    }
   ],
   "source": [
    "import os,pickle,sys,numpy,nn,copy,scipy,scipy.io\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.initializations import normal, identity\n",
    "import json\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "# --------------------------------------------\n",
    "# Parameters\n",
    "# --------------------------------------------\n",
    "root_folder_path = '/home/peng/Desktop/ Pynotebooks/Link to Machine_learning_for_reliability_analysis/QSAR/model_weihts/'\n",
    "seed  = 3453\n",
    "#print sys.argv\n",
    "splits = np.arange(0,1)\n",
    "\n",
    "mb    = 25     # size of the minibatch\n",
    "hist  = 0.1    # fraction of the history to be remembered\n",
    "\n",
    "hidden_size = 300\n",
    "\n",
    "dataset = scipy.io.loadmat('/home/peng/Documents/Project_C/QSAR_nlp/qm7.mat')\n",
    "for split in splits:\n",
    "\tprint \"this is the %d split\"%split\n",
    "\n",
    "\t# --------------------------------------------\n",
    "\t# Extract training data\n",
    "\t# --------------------------------------------\n",
    "\tP = dataset['P'][range(0,split)+range(split+1,5)].flatten()\n",
    "\t\n",
    "\tx_train = dataset['X'][P]\n",
    "\t\t\n",
    "\tx_label = dataset['T'][0,P]\n",
    "\t\n",
    "\tprint np.shape(x_label)\n",
    "\n",
    "\t# --------------------------------------------\n",
    "\t### Convert it to 1D for irnn\n",
    "\tx_train = x_train.reshape(x_train.shape[0], -1)\n",
    "\t#x_train /= x_train.reshape(x_train.shape[0], -1, 1)\n",
    "\tx_train = x_train.astype('float32')\n",
    "\tx_label = x_label.astype('float32')\n",
    "\tprint np.shape(x_train)\n",
    "\t\n",
    "\t# --------------------------------------------\n",
    "\t# Design the DNN model\n",
    "\t# --------------------------------------------\n",
    "\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(output_dim=hidden_size,\n",
    "\t                    #init=lambda shape, name: normal(shape, scale=0.001, name=name),\n",
    "\t                    #inner_init=lambda shape, name: identity(shape, scale=1.0, name=name),\n",
    "\t                    activation='relu',\n",
    "\t                    input_shape=x_train.shape[1:]))\n",
    "\tmodel.add(Dense(hidden_size, activation='relu'))\n",
    "\tmodel.add(Dense(hidden_size, activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\tmodel.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\",verbose=False)\n",
    "\n",
    "\tmodel.fit(x_train, x_label, batch_size=mb, nb_epoch=15),time.sleep(0.2)\n",
    "\n",
    "   \n",
    "    \n",
    "    ###design DNN and fit\n",
    "\n",
    "\n",
    "\t###save the weights\n",
    "\n",
    "\tmodel.save_weights(root_folder_path + 'nn_keras_%d'%split + \".h5\", overwrite=True)\t\n",
    "\twith open(root_folder_path + 'nn_keras_%d'%split + \".json\", \"w\") as outfile:\t\t\n",
    "\t    json.dump(model.to_json(), outfile)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print (\"The running takes %r min\" %((stop-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test set:\n",
      "[[ nan]\n",
      " [ nan]\n",
      " [ nan]\n",
      " ..., \n",
      " [ nan]\n",
      " [ nan]\n",
      " [ nan]]\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "import os,pickle,sys,numpy,copy,scipy,scipy.io\n",
    "import numpy as np\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.initializations import normal, identity\n",
    "import json\n",
    "\n",
    "\n",
    "root_folder_path = '/home/peng/Desktop/ Pynotebooks/Link to Machine_learning_for_reliability_analysis/QSAR/model_weihts/'\n",
    "# --------------------------------------------\n",
    "# Parameters\n",
    "# --------------------------------------------\n",
    "#split = int(sys.argv[1]) # test split for cross-validation (between 0 and 5)\n",
    "splits = np.arange(0,1)\n",
    "# --------------------------------------------\n",
    "# Load data and models\n",
    "# --------------------------------------------\n",
    "#if not os.path.exists('qm7.mat'): os.system('wget http://www.quantum-machine.org/data/qm7.mat')\n",
    "dataset = scipy.io.loadmat('/home/peng/Documents/Project_C/QSAR_nlp/qm7.mat')\n",
    "acc_mae = 0.0\n",
    "\n",
    "for split in splits:\n",
    "\twith open('/home/peng/Desktop/ Pynotebooks/Link to Machine_learning_for_reliability_analysis/QSAR/model_weihts/nn_keras%d'%split + \".json\", 'r') as jfile:\n",
    "\t\tmodel = model_from_json(json.load(jfile))\n",
    "\tmodel.load_weights('/home/peng/Desktop/ Pynotebooks/Link to Machine_learning_for_reliability_analysis/QSAR/model_weihts/nn_keras%d'%split + '.h5')\n",
    "\tmodel.compile(\"sgd\", \"mse\")\n",
    "\t\n",
    "#\tprint('results after %d iterations'%nn.nbiter)\n",
    "\t\n",
    "\tPtrain = dataset['P'][range(0,split)+range(split+1,5)].flatten()\n",
    "\t#Ptest  = dataset['P'][split]\n",
    "\tPtest  = dataset['P'][split-1]\n",
    "\tfor P,name in zip([Ptest],['test']):\n",
    "\t\t# --------------------------------------------\n",
    "\t\t# Extract test data\n",
    "\t\t# --------------------------------------------\n",
    "\t\tx_train = dataset['X'][P]\n",
    "\t\tx_train = x_train.reshape(x_train.shape[0], -1, 1)\n",
    "\t\tx_label = dataset['T'][0,P]\n",
    "\t\n",
    "\t\t# --------------------------------------------\n",
    "\t\t# Test the neural network\n",
    "\t\t# --------------------------------------------\n",
    "\t\tprint('\\n%s set:'%name)\n",
    "\t\tpredict_label = model.predict(x_train)\n",
    "        print predict_label\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t#print('MAE:  %5.2f kcal/mol'%numpy.abs(np.float(predict_label)-np.float(x_label).mean(axis=0))\n",
    "\n",
    "print ('finished')              \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
